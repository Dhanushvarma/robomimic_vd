# Model Configuration
input_dim: 64        # Dimension of the input state
output_dim : 4
hidden_dim  : 1024



# Training Configuration
learning_rate: 0.0001  # Learning rate for the optimizer
batch_size: 64        # Batch size for data loading
num_epochs: 15000        # Total number of training epochs
gradient_steps_per_epoch : 100
run_name : "Feb_5_trial_2"
dataset_path : "/home/dpenmets/LIRA_work/robomimic_vd/robomimic/scripts/final_cfgs/demo_data_with_gaze/low_dim_gaze.hdf5"

# wandb Integration
wandb_project: 'Feb_5'       # Project name in wandb
wandb_entity: 'lira_pato'         # Your wandb entity (username or team name)
wandb_name: 'Feb_5_plain_exp_2'       # Name for this particular run/experiment

# Checkpointing
checkpoint_dir: './checkpoints'    # Directory to save checkpoints
log_frequency : 1000

# DataLoader Configuration
num_workers: 4                      # Number of worker threads for data loading
